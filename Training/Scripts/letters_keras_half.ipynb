{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data - download in matlab format from:\n",
    "# https://www.nist.gov/itl/iad/image-group/emnist-dataset\n",
    "import scipy.io\n",
    "mat = scipy.io.loadmat('../Dataset/emnist-letters.mat')\n",
    "d = mat['dataset']\n",
    "X_train = d[0,0]['train'][0,0]['images']\n",
    "y_train = d[0,0]['train'][0,0]['labels']\n",
    "X_test = d[0,0]['test'][0,0]['images']\n",
    "y_test = d[0,0]['test'][0,0]['labels']\n",
    "\n",
    " # choosing the letters to learn\n",
    "half = dict();\n",
    "half['1'] = [1,2,3,6,7,9,10,13,16,19,21,23,24]\n",
    "half['2'] = [4,5,8,11,12,14,15,17,18,20,22,25,26]\n",
    "\n",
    "this = '2';\n",
    "\n",
    "ind = [val in half[this] for val in y_train]\n",
    "X_train = X_train[ind][:]\n",
    "y_train = y_train[ind]\n",
    "\n",
    "ind = [val in half[this] for val in y_test]\n",
    "X_test = X_test[ind][:]\n",
    "y_test = y_test[ind][:]\n",
    "\n",
    "\n",
    "#(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28,1).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(30, 5, 5, border_mode='valid', input_shape=(28,28,1), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(15, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))  # softmax\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model\n",
    "model = baseline_model()\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, \n",
    "          validation_split=.1,\n",
    "          nb_epoch=10, \n",
    "          batch_size=200, \n",
    "          verbose=True)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import coremltools\n",
    "coreml_model = coremltools.converters.keras.convert(model, input_names = ['imageAlpha'], output_names = ['letterConfidence'])\n",
    "\n",
    "coreml_model.author = 'Kate Bonnen and Conrad Stoll'\n",
    "coreml_model.license = 'MIT'\n",
    "coreml_model.short_description = \"Recognize the hand-drawn letter from an input image.\"\n",
    "\n",
    "coreml_model.input_description['imageAlpha'] = 'The input image alpha values, from top down, left to right.'\n",
    "coreml_model.output_description['letterConfidence'] = 'Confidence for each letter ranging from index 1 to 26. Ignore index 0.'\n",
    "\n",
    "coreml_model.save('../Models/letters_keras_half_' + this + '.mlmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
