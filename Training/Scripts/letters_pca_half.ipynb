{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the data - download in matlab format from:\n",
    "# https://www.nist.gov/itl/iad/image-group/emnist-dataset\n",
    "import scipy.io\n",
    "mat = scipy.io.loadmat('../Dataset/emnist-letters.mat')\n",
    "d = mat['dataset']\n",
    "images = d[0,0]['train'][0,0]['images']\n",
    "labels = d[0,0]['train'][0,0]['labels']\n",
    "test_images = d[0,0]['test'][0,0]['images']\n",
    "test_labels = d[0,0]['test'][0,0]['labels']\n",
    "\n",
    "\n",
    "which_half = '1'\n",
    "if which_half == '1':\n",
    "    half = [1,2,3,6,7,9,10,13,16,19,21,23,24]\n",
    "else:\n",
    "    half = [4,5,8,11,12,14,15,17,18,20,22,25,26]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "n= images.shape[0]\n",
    "# format training set\n",
    "images_2 = np.asarray(images[0:n][:],dtype=np.float64)/255\n",
    "labels_2 = np.asarray(labels[0:n],dtype=np.int32).ravel();\n",
    "training_ind = [i in half for i in labels_2]\n",
    "\n",
    "# format testing set\n",
    "test_images_2 = np.asarray(test_images,dtype=np.float64)/255\n",
    "test_labels_2 = np.asarray(test_labels,dtype=np.int32).ravel();\n",
    "testing_ind = [i in half for i in test_labels_2]\n",
    "\n",
    "# perform dimensionality reduction\n",
    "ncomps = 25;  # We'll reduce from 784 dimensions to 25\n",
    "pca = PCA(n_components=ncomps);\n",
    "pca.fit(images_2)\n",
    "# Those 25 dimensions still explain a lot of the variance\n",
    "print 'Explained Variance: ' + str(round(100*sum(pca.explained_variance_ratio_))) + '%'\n",
    "\n",
    "images_pca = pca.transform(images_2)\n",
    "images_pca = images_pca[training_ind][:]\n",
    "labels_2 = labels_2[training_ind]\n",
    "test_images_pca = pca.transform(test_images_2)\n",
    "test_images_pca = test_images_pca[testing_ind][:]\n",
    "test_labels_2 = test_labels_2[testing_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save pca matrix - This is the matrix that we will use to perform the transformation in the app\n",
    "mat = pca.components_\n",
    "pca_mat = mat.tolist()\n",
    "import csv\n",
    "with open('../Models/pca_matrix.csv','wb') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(pca_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn the model\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "nsamps = 20000\n",
    "from sklearn import svm\n",
    "clf = svm.SVC(probability=True)\n",
    "clf.fit(images_pca[:nsamps][:],labels_2[:nsamps])\n",
    "\n",
    "end = time.time()\n",
    "print( \"Time it took to learn the model: \" + str(end - start) + \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "answers = clf.predict(test_images_pca)\n",
    "end = time.time()\n",
    "print( \"Time it took to test the model: \" + str(end - start) + \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0;\n",
    "s=[i==j for i,j in zip(test_labels_2,answers)]\n",
    "incorrect=[i!=j for i,j in zip(test_labels_2,answers)]\n",
    "print(\"Percent Correct: \" + str(100*sum(s)/len(s)) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import coremltools\n",
    "coreml_model = coremltools.converters.sklearn.convert(clf, 'convertedPCAValues', output_feature_names='letterIndex')\n",
    "coreml_model.author = 'Kate Bonnen and Conrad Stoll'\n",
    "coreml_model.license = 'MIT'\n",
    "coreml_model.short_description = \"Recognize the hand-drawn letter from an input image.\"\n",
    "\n",
    "coreml_model.input_description['convertedPCAValues'] = 'The input image alpha values multiplied by a PCA matrix.'\n",
    "\n",
    "coreml_model.output_description['letterIndex'] = 'Most likely letter index, ranging from 1 to 26.'\n",
    "coreml_model.output_description['classProbability'] = 'The probability of each letter index.'\n",
    "\n",
    "coreml_model.save('../Models/letters_pca_half_' + which_half + '.mlmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
